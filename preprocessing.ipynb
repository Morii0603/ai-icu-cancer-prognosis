{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba4081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('final_selection.csv')\n",
    "df[\"icu_status\"] = df[\"icustay_seq\"].replace({2:1, np.nan:0, 3:1, 4:1, 5:1,1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9941e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df[\"icustay_seq\"]==1]\n",
    "df = df.sort_values(by=['subject_id', 'admittime']).groupby('subject_id').head(1)\n",
    "# df = df[df[\"icustay_seq\"]==1]\n",
    "df.drop_duplicates(subset=['subject_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1cf3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survival_30布:\n",
      "survival_30\n",
      "1    836\n",
      "0    301\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Morii\\AppData\\Local\\Temp\\ipykernel_1560\\1056783774.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['gender'] = df['gender'].replace({'M': 1, 'F': 0})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "# df[\"icustay_seq\"] = df[\"icustay_seq\"].replace({2:1, np.nan:0, 3:1, 4:1, 5:1})\n",
    "df['gender'] = df['gender'].replace({'M': 1, 'F': 0})\n",
    "df['dod'] = pd.to_datetime(df['dod'], format='%d/%m/%Y', errors='coerce')\n",
    "df['admittime'] = pd.to_datetime(df['admittime'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "df['dischtime'] = pd.to_datetime(df['dischtime'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "# 先计算死亡时间\n",
    "df['survival_time'] = (df['dod'] - df['admittime']).dt.days\n",
    "\n",
    "# 缺失（即生存/删失）时用出院时间\n",
    "df['survival_time'] = np.where(\n",
    "    df['survival_time'].isna(),\n",
    "    (df['dischtime'] - df['admittime']).dt.days,\n",
    "    df['survival_time']\n",
    ")\n",
    "df['outcome'] = df['dod'].notna().astype(int)\n",
    "# 创建survival_365列\n",
    "df['survival_30'] = ((df['outcome'] == 0) | (df['survival_time'] >= 30)).astype(int)\n",
    "\n",
    "# 打印分布情况\n",
    "print(\"survival_30布:\")\n",
    "print(df['survival_30'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tibc四个亚组的统计信息:\n",
      "   tibc_quantile_group  count  median  lower_bound  upper_bound\n",
      "0                    1    287   126.0           29          152\n",
      "1                    2    282   174.0          153          195\n",
      "2                    3    284   217.0          196          247\n",
      "3                    4    284   288.0          248          751\n",
      "ferritin四个亚组的统计信息:\n",
      "   ferritin_quantile_group  count  median  lower_bound  upper_bound\n",
      "0                        1    285   122.0          8.0        223.0\n",
      "1                        2    284   349.5        224.0        545.0\n",
      "2                        3    284   850.0        546.0       1319.0\n",
      "3                        4    284  2437.0       1321.0     200205.0\n",
      "iron四个亚组的统计信息:\n",
      "   iron_quantile_group  count  median  lower_bound  upper_bound\n",
      "0                    1    301    16.0            5           22\n",
      "1                    2    272    29.0           23           37\n",
      "2                    3    280    47.0           38           66\n",
      "3                    4    284   104.5           67          483\n",
      "transferrin四个亚组的统计信息:\n",
      "   transferrin_quantile_group  count  median  lower_bound  upper_bound\n",
      "0                           1    287    97.0           22          117\n",
      "1                           2    282   134.0          118          150\n",
      "2                           3    284   167.0          151          190\n",
      "3                           4    284   221.5          191          578\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 首先计算四分位数组\n",
    "df['tibc_quantile_group'] = pd.qcut(df['tibc'], q=4, labels=False) + 1\n",
    "df['ferritin_quantile_group'] = pd.qcut(df['ferritin'], q=4, labels=False) + 1\n",
    "df['iron_quantile_group'] = pd.qcut(df['iron'], q=4, labels=False) + 1\n",
    "df['transferrin_quantile_group'] = pd.qcut(df['transferrin'], q=4, labels=False) + 1\n",
    "\n",
    "# 获取tibc四个亚组的统计信息\n",
    "tibc_stats = df.groupby('tibc_quantile_group')['tibc'].agg([\n",
    "    ('count', 'count'),          # 每个亚组的样本数\n",
    "    ('median', 'median'),        # 中位数\n",
    "    ('lower_bound', 'min'),      # 下限（最小值）\n",
    "    ('upper_bound', 'max')       # 上限（最大值）\n",
    "]).reset_index()\n",
    "\n",
    "print(\"tibc四个亚组的统计信息:\")\n",
    "print(tibc_stats)\n",
    "\n",
    "\n",
    "ferritin_stats = df.groupby('ferritin_quantile_group')['ferritin'].agg([\n",
    "    ('count', 'count'),          # 每个亚组的样本数\n",
    "    ('median', 'median'),        # 中位数\n",
    "    ('lower_bound', 'min'),      # 下限（最小值）\n",
    "    ('upper_bound', 'max')       # 上限（最大值）\n",
    "]).reset_index()    \n",
    "print(\"ferritin四个亚组的统计信息:\")\n",
    "print(ferritin_stats)\n",
    "\n",
    "iron_stats = df.groupby('iron_quantile_group')['iron'].agg([\n",
    "    ('count', 'count'),          # 每个亚组的样本数\n",
    "    ('median', 'median'),        # 中位数\n",
    "    ('lower_bound', 'min'),      # 下限（最小值）\n",
    "    ('upper_bound', 'max')       # 上限（最大值）\n",
    "]).reset_index()    \n",
    "print(\"iron四个亚组的统计信息:\")\n",
    "print(iron_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abdf8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留非缺失值不少于 80% 的列（thresh 为最小非 NA 数量）\n",
    "df.dropna(axis=1, thresh=int(len(df) * 0.8), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f81cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['dischtime','admittime','hospital_expire_flag',\n",
    "                 'subject_id','hadm_id','icustay_seq', \"malignant_tumor\", \"icu_status\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed1421b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['survival_time']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df0b1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutrophils', 'lymphocytes', 'alt', 'ast', 'total_bilirubin', 'albumin', 'bun', 'creatinine', 'glucose', 'sodium', 'chloride', 'free_calcium', 'total_calcium', 'pao2', 'pco2', 'ph', 'lactate', 'anion_gap', 'inr', 'pt', 'ptt', 'resp_rate', 'temperature', 'weight_admit']\n"
     ]
    }
   ],
   "source": [
    "# 方法1 — 一行筛选\n",
    "cols_with_na = df.columns[df.dtypes.eq('float64') & df.isnull().any()].tolist()\n",
    "print(cols_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6daba15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 需要插补的列\n",
    "cols_to_impute = cols_with_na\n",
    "\n",
    "# 用重置索引的数据\n",
    "df_reset = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# 为每个需要插补的列指定预测变量（通常为除自身以外的所有列）\n",
    "variable_schema = {\n",
    "    col: [c for c in df_reset.columns if c != col]\n",
    "    for col in cols_to_impute\n",
    "}\n",
    "\n",
    "kernel = mf.ImputationKernel(\n",
    "    df_reset,\n",
    "    random_state=1991,\n",
    "    variable_schema=variable_schema\n",
    ")\n",
    "\n",
    "kernel.mice(iterations=5, n_imputations=5)\n",
    "\n",
    "# 拿到完整数据，但只有 cols_to_impute 会被替换为插补结果\n",
    "completed = kernel.complete_data(iteration=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19bc7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed.to_csv('final_imputed_with_sofa_firsticu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = df.drop(columns=[\"survival_time\",\"outcome\",\"survival_30\"])\n",
    "y = df[\"survival_30\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "# 2. 在训练集上创建并“拟合”miceforest内核\n",
    "# 这一步，miceforest只从X_train中学习插补模型\n",
    "kds_train = mf.ImputationKernel(\n",
    "    data=X_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 运行MICE算法（例如5次迭代）\n",
    "kds_train.mice(iterations=5)\n",
    "\n",
    "# 3. 获取插补后的训练集（通常取最后一次迭代的结果）\n",
    "X_train_imputed = kds_train.complete_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e804df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from tabpfn import TabPFNClassifier\n",
    "# 4. 关键步骤：使用在训练集上拟合好的内核来转换测试集\n",
    "# 注意：我们不会在测试集上重新运行MICE迭代，只是应用训练好的模型\n",
    "X_test_imputed = kds_train.impute_new_data(X_test)\n",
    "\n",
    "# 获取填充后的测试集数据\n",
    "X_test_imputed = X_test_imputed.complete_data()\n",
    "\n",
    "# 5. 现在，使用处理好的数据训练和评估模型\n",
    "model = TabPFNClassifier()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "score = model.score(X_test_imputed, y_test)\n",
    "\n",
    "print(f\"模型在测试集上的准确率: {score:.4f}\") # 这个结果是可信的\n",
    "# 预测概率（用于AUC计算）\n",
    "y_pred_proba = model.predict_proba(X_test_imputed)[:, 1]  # 取正类的概率\n",
    "\n",
    "# 预测类别（用于准确率计算）\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = model.score(X_test_imputed, y_test)\n",
    "\n",
    "# 计算AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"模型在测试集上的准确率: {accuracy:.4f}\")\n",
    "print(f\"模型在测试集上的AUC值: {auc_score:.4f}\")\n",
    "\n",
    "# 可选：绘制ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
